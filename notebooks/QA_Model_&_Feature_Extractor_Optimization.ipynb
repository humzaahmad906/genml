{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "QA_Model_&_Feature_Extractor_Optimization.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a0ef06c15b14496da01b239592f10bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4c06e8ce9624b32b56797d7f72fa68d",
       "IPY_MODEL_cdfc81d124354bf1a329f22c595852d9",
       "IPY_MODEL_d9c757df508944daabb0d13d50e1496b"
      ],
      "layout": "IPY_MODEL_5959295bcf9843d9b1a1203bb071f02c"
     }
    },
    "d4c06e8ce9624b32b56797d7f72fa68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d2a32dc0ef64f8b9d362978917f31b8",
      "placeholder": "​",
      "style": "IPY_MODEL_2fc20f5e83154a2b9f0c4dd7d83140c4",
      "value": "Downloading: 100%"
     }
    },
    "cdfc81d124354bf1a329f22c595852d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41a11af023264d809af04468e11a3e35",
      "max": 498,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04ec75fe4aca42a3b70bfa34203785fe",
      "value": 498
     }
    },
    "d9c757df508944daabb0d13d50e1496b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e464fb4ba31849c6a8156dc28a95b711",
      "placeholder": "​",
      "style": "IPY_MODEL_00820d3385294adfbfc1d891be3b0ca8",
      "value": " 498/498 [00:00&lt;00:00, 7.87kB/s]"
     }
    },
    "5959295bcf9843d9b1a1203bb071f02c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d2a32dc0ef64f8b9d362978917f31b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fc20f5e83154a2b9f0c4dd7d83140c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41a11af023264d809af04468e11a3e35": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04ec75fe4aca42a3b70bfa34203785fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e464fb4ba31849c6a8156dc28a95b711": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "00820d3385294adfbfc1d891be3b0ca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94ccc999334044cdbd502d5c5cf021bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18ba8f1c9abd448b99935ce008c00c23",
       "IPY_MODEL_78b99f15dbce47cb9aaf92c6b891b4d7",
       "IPY_MODEL_c8d23799f62b4cb2915c94b86332bf68"
      ],
      "layout": "IPY_MODEL_a9a885bc5b7e49778fc19675ed71cf58"
     }
    },
    "18ba8f1c9abd448b99935ce008c00c23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c10a910ceb074e24aff32369f64f5155",
      "placeholder": "​",
      "style": "IPY_MODEL_9a8544fb1e124d0f8a66cb98cc174a15",
      "value": "Downloading: 100%"
     }
    },
    "78b99f15dbce47cb9aaf92c6b891b4d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f2dad47f9da481cb185feab60ab4e06",
      "max": 571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51fdd1c8de3f491ea8f86cc86665ff5d",
      "value": 571
     }
    },
    "c8d23799f62b4cb2915c94b86332bf68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4854182869074745873f5d7f4a0d961c",
      "placeholder": "​",
      "style": "IPY_MODEL_8cde3c6bd0f44f6bbc1ec247925af7e2",
      "value": " 571/571 [00:00&lt;00:00, 11.6kB/s]"
     }
    },
    "a9a885bc5b7e49778fc19675ed71cf58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c10a910ceb074e24aff32369f64f5155": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a8544fb1e124d0f8a66cb98cc174a15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f2dad47f9da481cb185feab60ab4e06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51fdd1c8de3f491ea8f86cc86665ff5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4854182869074745873f5d7f4a0d961c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cde3c6bd0f44f6bbc1ec247925af7e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "us2326B97g0w",
    "outputId": "80927cf3-8cfe-4805-9b50-723c41771fdc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "  Using cached transformers-4.21.1-py3-none-any.whl (4.7 MB)\r\n",
      "Requirement already satisfied: requests in /home/humza/miniconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\r\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\r\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 6.6 MB 2.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting regex!=2019.12.17\r\n",
      "  Downloading regex-2022.7.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 765 kB 82 kB/s eta 0:00:011\r\n",
      "\u001B[?25hCollecting pyyaml>=5.1\r\n",
      "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 661 kB 693 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/humza/miniconda3/lib/python3.9/site-packages (from transformers) (4.63.0)\r\n",
      "Collecting filelock\r\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\r\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\r\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 101 kB 769 kB/s ta 0:00:011\r\n",
      "\u001B[?25hCollecting numpy>=1.17\r\n",
      "  Downloading numpy-1.23.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 17.1 MB 1.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting typing-extensions>=3.7.4.3\r\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/humza/miniconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\r\n",
      "Installing collected packages: typing-extensions, pyyaml, filelock, tokenizers, regex, numpy, huggingface-hub, transformers\r\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.8.1 numpy-1.23.1 pyyaml-6.0 regex-2022.7.25 tokenizers-0.12.1 transformers-4.21.1 typing-extensions-4.3.0\r\n",
      "Collecting git+https://github.com/huggingface/optimum.git\r\n",
      "  Cloning https://github.com/huggingface/optimum.git to /tmp/pip-req-build-8esgx8d0\r\n",
      "  Running command git clone -q https://github.com/huggingface/optimum.git /tmp/pip-req-build-8esgx8d0\r\n",
      "  Resolved https://github.com/huggingface/optimum.git to commit 69f2883d945ccc669bdd0c78e0ba8fe4265c6792\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h    Preparing wheel metadata ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /home/humza/miniconda3/lib/python3.9/site-packages (from optimum==1.4.0.dev0) (1.23.1)\r\n",
      "Requirement already satisfied: packaging in /home/humza/miniconda3/lib/python3.9/site-packages (from optimum==1.4.0.dev0) (21.3)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from optimum==1.4.0.dev0) (0.8.1)\r\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.20.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from optimum==1.4.0.dev0) (4.21.1)\r\n",
      "Collecting torch>=1.9\r\n",
      "  Downloading torch-1.12.1-cp39-cp39-manylinux1_x86_64.whl (776.4 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 776.4 MB 20 kB/s  eta 0:00:014   |████                            | 98.5 MB 1.3 MB/s eta 0:09:01     |███████████████▊                | 380.2 MB 882 kB/s eta 0:07:29     |████████████████▎               | 395.9 MB 884 kB/s eta 0:07:11\r\n",
      "\u001B[?25hCollecting sympy\r\n",
      "  Downloading sympy-1.10.1-py3-none-any.whl (6.4 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 6.4 MB 674 kB/s eta 0:00:01     |█████████████████████████████▌  | 5.9 MB 674 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting coloredlogs\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 46 kB 1.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (4.3.0)\r\n",
      "Requirement already satisfied: requests in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (2.27.1)\r\n",
      "Requirement already satisfied: tqdm in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (4.63.0)\r\n",
      "Requirement already satisfied: filelock in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (3.8.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (6.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/humza/miniconda3/lib/python3.9/site-packages (from packaging->optimum==1.4.0.dev0) (3.0.9)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/humza/miniconda3/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.20.1->optimum==1.4.0.dev0) (2022.7.25)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.20.1->optimum==1.4.0.dev0) (0.12.1)\r\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91\r\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.3 MB 924 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting protobuf<=3.20.1\r\n",
      "  Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.0 MB 1.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting humanfriendly>=9.1\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 86 kB 1.9 MB/s eta 0:00:011\r\n",
      "\u001B[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (1.26.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.4.0.dev0) (2.0.4)\r\n",
      "Collecting mpmath>=0.19\r\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 532 kB 1.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hBuilding wheels for collected packages: optimum\r\n",
      "  Building wheel for optimum (PEP 517) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for optimum: filename=optimum-1.4.0.dev0-py3-none-any.whl size=125728 sha256=d0b42c92fb37788f90c3a8cdbe427a1b11a321249e1ba4a1f17a29ea1fd33898\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mdq5unvf/wheels/a2/2f/00/2a677c0c9bccd235c10e1cda441d7bb0d48ab534cff60239e1\r\n",
      "Successfully built optimum\r\n",
      "Installing collected packages: sentencepiece, protobuf, mpmath, humanfriendly, torch, sympy, coloredlogs, optimum\r\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 mpmath-1.2.1 optimum-1.4.0.dev0 protobuf-3.20.1 sentencepiece-0.1.97 sympy-1.10.1 torch-1.12.1\r\n",
      "Collecting onnxruntime\r\n",
      "  Downloading onnxruntime-1.12.1-cp39-cp39-manylinux_2_27_x86_64.whl (4.9 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 4.9 MB 919 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: packaging in /home/humza/miniconda3/lib/python3.9/site-packages (from onnxruntime) (21.3)\r\n",
      "Requirement already satisfied: protobuf in /home/humza/miniconda3/lib/python3.9/site-packages (from onnxruntime) (3.20.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from onnxruntime) (1.23.1)\r\n",
      "Collecting flatbuffers\r\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: sympy in /home/humza/miniconda3/lib/python3.9/site-packages (from onnxruntime) (1.10.1)\r\n",
      "Requirement already satisfied: coloredlogs in /home/humza/miniconda3/lib/python3.9/site-packages (from onnxruntime) (15.0.1)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from coloredlogs->onnxruntime) (10.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/humza/miniconda3/lib/python3.9/site-packages (from packaging->onnxruntime) (3.0.9)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/humza/miniconda3/lib/python3.9/site-packages (from sympy->onnxruntime) (1.2.1)\r\n",
      "Installing collected packages: flatbuffers, onnxruntime\r\n",
      "Successfully installed flatbuffers-2.0 onnxruntime-1.12.1\r\n",
      "Collecting onnx\r\n",
      "  Downloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 13.1 MB 1.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /home/humza/miniconda3/lib/python3.9/site-packages (from onnx) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from onnx) (4.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/humza/miniconda3/lib/python3.9/site-packages (from onnx) (1.23.1)\r\n",
      "Installing collected packages: onnx\r\n",
      "Successfully installed onnx-1.12.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!python -m pip install git+https://github.com/huggingface/optimum.git\n",
    "!pip install onnxruntime\n",
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmarking"
   ],
   "metadata": {
    "id": "iZmyw099C7lz",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction"
   ],
   "metadata": {
    "id": "0rrypFygicbb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Base Model Load\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "raC34vqLC_cv",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"microsoft/codebert-base\"\n",
    "task = \"feature-extraction\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# test the model with using transformers pipeline, with handle_impossible_answer for squad_v2 \n",
    "feature_extractor = pipeline(task, model=model_id, tokenizer=tokenizer, handle_impossible_answer=True)\n"
   ],
   "metadata": {
    "id": "v9BQSmhwC-TD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "prediction = feature_extractor([\"What's my name?\"])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVXsiNeXETwS",
    "outputId": "6fc410bb-54d1-43e6-f01b-a2589ebd0b11",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 142 ms, sys: 0 ns, total: 142 ms\n",
      "Wall time: 74.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "[-0.1326238065958023,\n 0.38220053911209106,\n 0.03749421238899231,\n -0.02008284255862236,\n 0.10234289616346359,\n -0.16812247037887573,\n -0.08768516778945923,\n 0.04570560157299042,\n 0.04813437908887863,\n -0.11880657821893692,\n 0.1357186734676361,\n 0.4343635141849518,\n -0.14596402645111084,\n -0.04268614202737808,\n 0.20766493678092957,\n 0.03773442283272743,\n 0.07840951532125473,\n 0.1304922252893448,\n 0.081199049949646,\n 0.07399129867553711,\n -0.17183847725391388,\n -0.14073914289474487,\n 0.23667697608470917,\n 0.0006463321624323726,\n 0.42707276344299316,\n 0.04345940798521042,\n 0.3349607586860657,\n 0.2065361589193344,\n 0.05771685391664505,\n 0.4824593961238861,\n -0.08865801244974136,\n -0.024739718064665794,\n 1.4476032257080078,\n -0.14148235321044922,\n 0.22061589360237122,\n -0.03208843618631363,\n -0.02742939628660679,\n 0.2644815742969513,\n -0.09928885847330093,\n 0.04172520712018013,\n -0.4197045564651489,\n -0.04511818662285805,\n -0.9629356861114502,\n 0.13015048205852509,\n 0.3906705677509308,\n -0.0413559228181839,\n -0.059324588626623154,\n 0.21776753664016724,\n -0.035730939358472824,\n 0.08466952294111252,\n 0.10513326525688171,\n 0.10072626918554306,\n -0.44987329840660095,\n -0.18779894709587097,\n -0.1052417978644371,\n 0.32319551706314087,\n -0.8032743334770203,\n 0.22859665751457214,\n -0.24708789587020874,\n -0.08324861526489258,\n -0.1758371889591217,\n -0.09789527952671051,\n -0.03620295226573944,\n -0.23983605206012726,\n 1.3852049112319946,\n -0.019930385053157806,\n 0.31752249598503113,\n 0.7986961603164673,\n -0.18854093551635742,\n 0.06854478269815445,\n 0.06854482740163803,\n -0.01488069724291563,\n -0.0978270024061203,\n -0.3220958113670349,\n -0.4060736298561096,\n 0.11598431318998337,\n -0.10323958098888397,\n 0.04085523262619972,\n -0.24323919415473938,\n 0.24399971961975098,\n 0.3370681703090668,\n -0.10445073992013931,\n 0.5116534233093262,\n 0.2608228325843811,\n -0.08986465632915497,\n 0.08385201543569565,\n 0.06848888844251633,\n 0.14716792106628418,\n -0.6163193583488464,\n 0.13704970479011536,\n 0.19641223549842834,\n 0.1482287049293518,\n 0.5605666637420654,\n -0.05228589475154877,\n -0.11486154049634933,\n 0.3363092839717865,\n 0.03681802749633789,\n -0.4724624454975128,\n 0.052591755986213684,\n -0.09624117612838745,\n 0.09887855499982834,\n -0.2906671464443207,\n 0.24007388949394226,\n -0.08204887062311172,\n 0.1758284568786621,\n -0.15723098814487457,\n 0.2746565639972687,\n -0.04381760209798813,\n 0.01633104681968689,\n -0.09796780347824097,\n -0.07601216435432434,\n -0.11276219040155411,\n 0.12785646319389343,\n 0.04268580675125122,\n 0.028880096971988678,\n -0.18128159642219543,\n -0.061486028134822845,\n 0.0050476244650781155,\n -0.15788498520851135,\n -0.06407606601715088,\n -0.774587094783783,\n 0.1680101603269577,\n -0.28438201546669006,\n 0.745708167552948,\n -0.0887305960059166,\n 0.04995180293917656,\n -0.15325339138507843,\n -0.02317924238741398,\n 0.05655030533671379,\n 0.4439873695373535,\n -0.8866024017333984,\n -0.7460301518440247,\n 0.0062853931449353695,\n 0.22009456157684326,\n 0.4106105864048004,\n -0.18628376722335815,\n -0.1009569764137268,\n 0.07066068053245544,\n -0.1095815971493721,\n 0.21841442584991455,\n -0.40270572900772095,\n -0.0042848847806453705,\n 0.10889990627765656,\n 0.1601383537054062,\n 0.47513434290885925,\n 0.06715469807386398,\n 0.11896509677171707,\n 0.11919405311346054,\n 0.018943920731544495,\n -0.29989948868751526,\n -0.468420147895813,\n 0.042662426829338074,\n 0.942552924156189,\n -0.33798637986183167,\n -0.00019393369439058006,\n -0.47610968351364136,\n 0.10857698321342468,\n -0.18871524930000305,\n 0.14329509437084198,\n -0.5400490760803223,\n 0.25593215227127075,\n -0.26348552107810974,\n 0.07121533155441284,\n 0.49229204654693604,\n 0.09830617159605026,\n 0.20229293406009674,\n -0.16629670560359955,\n -0.20355606079101562,\n 0.21400760114192963,\n 0.13290376961231232,\n -0.2244558483362198,\n -0.31925395131111145,\n -0.49857810139656067,\n -0.006475892383605242,\n 0.04163564369082451,\n 0.24895255267620087,\n -0.14431782066822052,\n -0.031810611486434937,\n -0.054568782448768616,\n 1.3062968254089355,\n -0.037534262984991074,\n -0.1844855695962906,\n 0.0871892124414444,\n -0.18511906266212463,\n 0.0007680443814024329,\n 0.13234943151474,\n -0.11660083383321762,\n 0.09533510357141495,\n 0.08905192464590073,\n -0.06608903408050537,\n -0.04090854898095131,\n -0.07288340479135513,\n 0.08571427315473557,\n 0.06972552835941315,\n 0.1730518341064453,\n 0.21453675627708435,\n -0.05589335411787033,\n 0.23830905556678772,\n 0.7229868173599243,\n -0.2243870049715042,\n -0.016163073480129242,\n 0.15738347172737122,\n 0.07728883624076843,\n 0.05211860314011574,\n 0.18478591740131378,\n 0.2751361131668091,\n -0.1952694207429886,\n 0.191459059715271,\n 0.21300584077835083,\n 0.9269945621490479,\n 1.637231707572937,\n 0.0031537783797830343,\n -0.0525483712553978,\n -0.27878713607788086,\n -0.6269187331199646,\n 0.0017651863163337111,\n -0.26612329483032227,\n 0.015312434174120426,\n -0.23786881566047668,\n -0.041411884129047394,\n -1.1838054656982422,\n 0.12775938212871552,\n -0.23322975635528564,\n -0.2528887391090393,\n -0.09828013181686401,\n -0.0012271935120224953,\n 0.32057327032089233,\n -0.12416180223226547,\n -0.13182218372821808,\n -0.028596701100468636,\n -0.009492713026702404,\n -0.10315467417240143,\n 0.018067991361021996,\n 0.06581823527812958,\n -0.24121823906898499,\n -0.2654077708721161,\n -0.07999531924724579,\n -0.04102936387062073,\n -0.04640841484069824,\n -0.9966239333152771,\n -0.10893512517213821,\n -0.04968629404902458,\n 0.34842121601104736,\n 0.33663874864578247,\n 0.20489570498466492,\n -0.321778804063797,\n 0.008628997951745987,\n 0.21748214960098267,\n -0.07390228658914566,\n 0.1760752946138382,\n -0.08474501222372055,\n 0.042359136044979095,\n -0.018234435468912125,\n 0.10750489681959152,\n -0.18457600474357605,\n -0.1988818198442459,\n -0.1711421012878418,\n -0.05521341785788536,\n 0.24628807604312897,\n 1.6466842889785767,\n -0.1541353315114975,\n 0.27230823040008545,\n 0.0630558431148529,\n -0.572663426399231,\n 0.043800655752420425,\n -0.6940868496894836,\n -0.004162397235631943,\n 0.054367415606975555,\n 0.3984796702861786,\n 0.3443582057952881,\n 1.1319295167922974,\n 0.25165435671806335,\n 0.06705988943576813,\n 0.3022039830684662,\n -0.08752482384443283,\n -0.03558929264545441,\n 0.3663763403892517,\n 0.00834168866276741,\n -0.5891823768615723,\n -0.044013746082782745,\n -0.17869198322296143,\n -0.15879479050636292,\n -0.01412870828062296,\n 0.09006115049123764,\n -0.18768419325351715,\n -0.049826234579086304,\n -0.3079356849193573,\n 0.03050323948264122,\n -0.07229271531105042,\n 0.041433822363615036,\n 0.3054503798484802,\n -0.4272170066833496,\n 0.9283793568611145,\n 0.14211809635162354,\n -0.3658899962902069,\n 0.2935035526752472,\n 0.13339471817016602,\n 0.32171371579170227,\n 0.04904087632894516,\n -0.1615234911441803,\n 0.05471169203519821,\n 0.15333421528339386,\n -0.2850354313850403,\n -0.1885124295949936,\n -0.2589520812034607,\n -0.2368282824754715,\n -0.37900108098983765,\n 0.0894547626376152,\n 0.24705785512924194,\n -0.027426350861787796,\n 0.24036560952663422,\n -0.6779214143753052,\n -0.1437646746635437,\n -0.156769260764122,\n 0.0602417066693306,\n -0.1499580293893814,\n -0.07415755838155746,\n 0.09568754583597183,\n -0.08248026669025421,\n -0.013399254530668259,\n 0.15723951160907745,\n -0.16615895926952362,\n 0.552011251449585,\n -1.0340766906738281,\n 0.11862760037183762,\n 0.4889024794101715,\n 0.10215716809034348,\n -0.20435939729213715,\n -1.4274905920028687,\n 0.831151008605957,\n -1.057071566581726,\n -0.010398109443485737,\n 0.027700381353497505,\n 0.759601354598999,\n -0.8142953515052795,\n -0.0908159613609314,\n 0.5035190582275391,\n -0.18251831829547882,\n 0.18087433278560638,\n -0.20333382487297058,\n -0.9953683018684387,\n 0.09898019582033157,\n -0.17960117757320404,\n 0.1360539346933365,\n -0.15748797357082367,\n 0.7306666374206543,\n -0.11996601521968842,\n -0.07586142420768738,\n 0.8484039306640625,\n 0.0594356432557106,\n -0.24701640009880066,\n -0.5314568281173706,\n -0.19682735204696655,\n -0.3870280385017395,\n -0.026838531717658043,\n 1.7844210863113403,\n 0.37262025475502014,\n -0.1373112052679062,\n -0.1502712368965149,\n -0.11810470372438431,\n 0.06738321483135223,\n -0.05249432846903801,\n 0.011295589618384838,\n 1.5498178005218506,\n 0.6759636402130127,\n -0.20959819853305817,\n -0.4979438781738281,\n -0.03415089100599289,\n -0.06248459219932556,\n 0.01724051497876644,\n 0.18122068047523499,\n 0.26508674025535583,\n -0.0021410989575088024,\n -0.005523681174963713,\n 0.10960249602794647,\n -0.24344594776630402,\n -0.14562079310417175,\n -0.08454006165266037,\n -0.011337414383888245,\n 0.23815405368804932,\n -0.6893037557601929,\n 0.11788928508758545,\n 0.22283917665481567,\n 0.009385179728269577,\n -0.07394922524690628,\n -1.8141942024230957,\n 0.1893802285194397,\n -0.09728226810693741,\n 0.956139326095581,\n 0.015312343835830688,\n 0.05075359717011452,\n 0.08835392445325851,\n 0.15827250480651855,\n -0.11954416334629059,\n -0.14400087296962738,\n 0.030835162848234177,\n -0.08521014451980591,\n 0.10062973946332932,\n -0.4139595031738281,\n -0.22673264145851135,\n -0.17424003779888153,\n -0.184890478849411,\n -0.07082639634609222,\n -0.030092889443039894,\n 0.07294289022684097,\n 0.33382004499435425,\n -0.42223885655403137,\n -0.16961638629436493,\n -0.275562047958374,\n 0.43417850136756897,\n -0.28594970703125,\n 1.3906309604644775,\n -0.22875073552131653,\n 0.18490295112133026,\n -0.035739101469516754,\n 0.07887190580368042,\n 0.1887121945619583,\n -0.3302680552005768,\n -0.005358146503567696,\n 0.11151915788650513,\n 0.14093604683876038,\n 0.19734832644462585,\n 0.2953612208366394,\n -0.17549292743206024,\n 0.05135625600814819,\n 0.01903647743165493,\n 0.032056257128715515,\n -0.20649152994155884,\n -0.02641845867037773,\n -0.14403285086154938,\n -0.12938694655895233,\n 0.17055854201316833,\n -0.016601674258708954,\n 0.25577792525291443,\n -0.30855366587638855,\n -0.08026249706745148,\n -0.3553828001022339,\n -0.2805005609989166,\n 0.35727497935295105,\n 0.012474451214075089,\n 0.23536904156208038,\n -0.1800481230020523,\n 0.10735701769590378,\n 0.13563746213912964,\n -0.2598956525325775,\n 0.21916845440864563,\n 0.4647127091884613,\n 1.1766045093536377,\n -0.009661675430834293,\n -0.16822294890880585,\n 0.05776234716176987,\n 0.24771438539028168,\n -0.02631920576095581,\n -0.03199165314435959,\n 0.3546140491962433,\n -0.0429549477994442,\n 0.0942448228597641,\n -0.007625351659953594,\n 0.3410627841949463,\n 0.39809650182724,\n -0.0008449117303825915,\n -0.0647837445139885,\n 0.18683113157749176,\n -0.2040242999792099,\n 0.10754671692848206,\n -1.3256763219833374,\n 0.3337228298187256,\n -0.0784638300538063,\n -0.2510465085506439,\n 0.18082661926746368,\n -0.6941621899604797,\n 0.17194536328315735,\n -0.1247270330786705,\n -0.19323410093784332,\n -0.15679055452346802,\n 0.018222065642476082,\n 0.12770259380340576,\n 1.343855857849121,\n 0.13785617053508759,\n 1.468298316001892,\n -0.24489232897758484,\n -0.19360828399658203,\n 0.19186723232269287,\n -0.5390692949295044,\n 0.015505367890000343,\n 0.060070622712373734,\n 0.07259822636842728,\n 0.203006774187088,\n -0.12051588296890259,\n -0.4463821351528168,\n -0.18324755132198334,\n -0.04381556063890457,\n -0.005368923768401146,\n 0.22230948507785797,\n 0.25483474135398865,\n 0.19920271635055542,\n 0.1817566305398941,\n 0.1892429143190384,\n -0.14674699306488037,\n 0.5768027901649475,\n 0.10788968950510025,\n 0.22778838872909546,\n 0.2189251184463501,\n 1.2169485092163086,\n -0.04898322746157646,\n 0.01959666982293129,\n -0.0883961021900177,\n 0.6984487175941467,\n 0.007388662081211805,\n -0.16603785753250122,\n -0.12368110567331314,\n 0.10860303044319153,\n 0.8429588675498962,\n 0.07103167474269867,\n 0.0009571771370247006,\n 0.1262950748205185,\n -0.11593440920114517,\n -0.165261372923851,\n 0.009874537587165833,\n 1.2378945350646973,\n 0.13856977224349976,\n -0.19145861268043518,\n -0.17111501097679138,\n 0.09245939552783966,\n 1.3171621561050415,\n 0.0592464953660965,\n -0.6932390928268433,\n -0.8206843733787537,\n 0.2649995684623718,\n -0.02775784581899643,\n -0.264228880405426,\n -0.07226170599460602,\n -0.03886851668357849,\n -0.03729838505387306,\n 0.7233211994171143,\n -0.07460974156856537,\n 0.07139448821544647,\n -0.2065325528383255,\n 0.014853458851575851,\n -0.02845953218638897,\n -0.1815958023071289,\n -0.2584150731563568,\n 1.084336280822754,\n 0.07463094592094421,\n 0.31923726201057434,\n -0.02320616878569126,\n -0.0011508917668834329,\n -1.0297181606292725,\n -0.11122564226388931,\n -0.14894604682922363,\n -0.04843970760703087,\n -1.2180482149124146,\n -0.20430703461170197,\n -0.03506949543952942,\n 0.2318483293056488,\n -0.03321608155965805,\n -0.10463772714138031,\n 0.3247419595718384,\n -0.1926269680261612,\n -0.019592534750699997,\n -0.21094363927841187,\n 0.05668727681040764,\n 0.2203993797302246,\n -0.02645619958639145,\n -0.10753690451383591,\n 0.34688612818717957,\n 0.07368842512369156,\n -0.07167308032512665,\n -0.11131601780653,\n -0.055115893483161926,\n -1.630237102508545,\n 0.06780123710632324,\n 0.09474188834428787,\n 0.0006243037059903145,\n 0.05149936303496361,\n 0.18781039118766785,\n 0.8582491874694824,\n -0.09283429384231567,\n 0.2255232334136963,\n 0.30376574397087097,\n 0.09092888981103897,\n 1.1338493824005127,\n 0.12871263921260834,\n -0.2223820835351944,\n -0.12818396091461182,\n 0.4230019748210907,\n 0.14662472903728485,\n 0.6695078015327454,\n 14.60053539276123,\n -0.25173288583755493,\n 0.962685227394104,\n 0.5103899836540222,\n 0.14932209253311157,\n -0.23785513639450073,\n -0.9501091241836548,\n -0.20775991678237915,\n -0.15561842918395996,\n -0.06669849902391434,\n 0.0615900456905365,\n 0.0650266781449318,\n -0.1418348252773285,\n -0.16358254849910736,\n 0.5679969787597656,\n -0.14511246979236603,\n -0.2263624519109726,\n 0.14018256962299347,\n 0.0563519224524498,\n -0.13036216795444489,\n -0.12563930451869965,\n 0.3094445466995239,\n 0.5049365758895874,\n -0.4773436188697815,\n 0.19626770913600922,\n -0.01871052198112011,\n 0.2501159608364105,\n 0.16879737377166748,\n -0.05018741637468338,\n -0.09395107626914978,\n -0.1022602766752243,\n 0.333568274974823,\n -0.2892247140407562,\n -0.14941835403442383,\n -0.023502206429839134,\n 1.2398275136947632,\n 0.023188479244709015,\n -0.19248096644878387,\n -0.10868013650178909,\n -1.1049555540084839,\n 0.1920645833015442,\n -0.6441420316696167,\n 0.2945200800895691,\n 0.042722392827272415,\n 0.2600304186344147,\n 0.09335701167583466,\n -0.5888080596923828,\n 0.2711094617843628,\n -0.08060835301876068,\n -0.16576336324214935,\n 0.020022904500365257,\n 0.5558308362960815,\n 0.1447771042585373,\n -0.11980456113815308,\n 0.12038208544254303,\n -0.15428315103054047,\n -0.5788218975067139,\n -0.14642278850078583,\n -0.8132330179214478,\n -0.16074615716934204,\n -0.07303552329540253,\n 0.16037239134311676,\n 0.14504466950893402,\n -1.1131210327148438,\n -0.10601825267076492,\n 0.012551485560834408,\n -0.010220474563539028,\n -0.030969321727752686,\n -0.06601148098707199,\n 0.13039910793304443,\n 1.5307468175888062,\n 1.0706852674484253,\n 0.02340037003159523,\n -0.14300470054149628,\n -0.2553461790084839,\n -0.014350512064993382,\n 0.11976649612188339,\n -0.185984805226326,\n 0.25668686628341675,\n -0.24153880774974823,\n 0.0037689507007598877,\n 0.004438316449522972,\n -0.014401779510080814,\n -0.3202880024909973,\n -0.04234764724969864,\n 0.24627943336963654,\n 0.28483885526657104,\n 0.24951733648777008,\n 1.133874535560608,\n -0.02601107954978943,\n -0.039328474551439285,\n -0.054762065410614014,\n -0.8697959184646606,\n -0.09383875876665115,\n 0.061725784093141556,\n -0.10986320674419403,\n -0.9916828274726868,\n -0.25587770342826843,\n 0.14916929602622986,\n 0.05475122109055519,\n 0.07944603264331818,\n -0.16951504349708557,\n 0.1273711621761322,\n 0.18596002459526062,\n -0.20093093812465668,\n -0.5657287240028381,\n 0.22573024034500122,\n -0.08267565816640854,\n 0.2170386016368866,\n 0.1414024829864502,\n -0.10979659855365753,\n -0.1433718055486679,\n -0.09455377608537674,\n -0.09197720885276794,\n 1.404191017150879,\n -0.06526809930801392,\n -0.06396733969449997,\n -0.0717422142624855,\n 0.3022957146167755,\n -0.11735937744379044,\n 0.08832599222660065,\n 0.7298189997673035,\n -0.21700464189052582,\n -0.15164287388324738,\n 0.09006273746490479,\n -0.04862753674387932,\n -0.158918097615242,\n 0.07184109091758728,\n 0.06215611845254898,\n 0.4721202254295349,\n -0.22324998676776886,\n 0.11818051338195801,\n 0.22497093677520752,\n 1.3906431198120117,\n 0.08159418404102325,\n -0.11593498289585114,\n -0.7157917618751526,\n -0.2044457197189331,\n 0.14621183276176453,\n 0.021795758977532387,\n -0.05519169569015503,\n -0.2080572098493576,\n 0.20056317746639252,\n 0.0020264864433556795,\n -0.8747062087059021,\n 0.1130622923374176,\n 0.5987281799316406,\n 0.07901875674724579,\n 0.06848203390836716,\n -0.06458810716867447,\n -0.021761657670140266,\n 0.30824705958366394,\n 0.03723325580358505,\n -0.09881410002708435,\n 0.029914943501353264,\n -0.18222512304782867,\n -0.037043098360300064,\n 0.9137684106826782,\n 0.4478640854358673,\n -0.35206711292266846,\n 0.1995270550251007,\n -0.7739831209182739,\n 0.34209364652633667,\n -0.22904452681541443,\n -0.08469335734844208,\n 0.06839029490947723,\n 0.34626561403274536,\n 0.07535070180892944,\n 0.28673094511032104,\n -0.2811368703842163,\n 0.24286943674087524,\n -0.06528864055871964,\n -0.5053550601005554,\n 0.41362911462783813,\n -0.16064178943634033,\n 0.06610507518053055,\n 0.43292495608329773,\n -0.07988981902599335,\n -0.32724159955978394,\n 0.33552345633506775]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimized Model"
   ],
   "metadata": {
    "id": "ONWx3fMnEceB",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "\n",
    "model_id = \"microsoft/codebert-base\"\n",
    "onnx_path = Path(\"onnx\")\n",
    "task = \"feature-extraction\"\n",
    "\n",
    "# load vanilla transformers and convert to onnx\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_id, from_transformers=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# save onnx checkpoint and tokenizer\n",
    "model.save_pretrained(onnx_path)\n",
    "tokenizer.save_pretrained(onnx_path)\n",
    "\n",
    "# test the model with using transformers pipeline, with handle_impossible_answer for squad_v2\n",
    "optimum_feature_extractor = pipeline(task, model=model, tokenizer=tokenizer, handle_impossible_answer=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a0ef06c15b14496da01b239592f10bef",
      "d4c06e8ce9624b32b56797d7f72fa68d",
      "cdfc81d124354bf1a329f22c595852d9",
      "d9c757df508944daabb0d13d50e1496b",
      "5959295bcf9843d9b1a1203bb071f02c",
      "3d2a32dc0ef64f8b9d362978917f31b8",
      "2fc20f5e83154a2b9f0c4dd7d83140c4",
      "41a11af023264d809af04468e11a3e35",
      "04ec75fe4aca42a3b70bfa34203785fe",
      "e464fb4ba31849c6a8156dc28a95b711",
      "00820d3385294adfbfc1d891be3b0ca8"
     ]
    },
    "id": "Q4uWoNZtEYxj",
    "outputId": "cdc20373-ffa0-4cfa-c534-fb134c5ca973",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 498/498 [00:00<00:00, 320kB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 632/632 [00:00<00:00, 235kB/s]\n",
      "Downloading: 100%|██████████| 90.9M/90.9M [01:34<00:00, 957kB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"optimum/all-MiniLM-L6-v2\")\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(\"optimum/all-MiniLM-L6-v2\")\n",
    "onnx_extractor = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"My name is Philipp and I live in Germany.\"\n",
    "pred = onnx_extractor(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-1.7761e-02,  5.6114e-04,  3.5539e-02, -6.2987e-03, -3.5684e-02,\n",
      "         -2.4026e-03,  1.7687e-02, -1.1022e-02,  3.4272e-02, -3.0947e-02,\n",
      "          1.8242e-02, -1.4128e-01, -4.1095e-02, -5.7751e-02, -6.9208e-03,\n",
      "         -5.6833e-02,  4.8729e-03,  6.4637e-02, -5.7160e-03, -4.4907e-02,\n",
      "         -7.1940e-02, -7.0136e-02,  3.7376e-02, -3.9940e-02,  1.1398e-02,\n",
      "          3.8127e-03,  2.6768e-02,  4.8390e-02, -4.0072e-03, -3.2384e-02,\n",
      "          6.3038e-02,  5.5875e-03,  2.7129e-02,  3.2292e-02,  4.5151e-02,\n",
      "         -1.4375e-02, -9.7354e-02, -9.1670e-03, -6.2466e-02,  5.1693e-02,\n",
      "          1.8237e-02, -3.6210e-02,  2.6908e-02,  1.2771e-02, -8.0993e-03,\n",
      "          1.6693e-02, -2.5291e-02,  1.3691e-01,  4.0347e-02,  7.6774e-02,\n",
      "         -7.7586e-02, -1.8439e-02,  2.8717e-02,  4.4411e-02,  1.7344e-03,\n",
      "          2.8095e-02,  4.6564e-03,  3.8210e-02, -4.1572e-03,  4.4834e-02,\n",
      "         -7.0689e-02,  2.8311e-02, -1.0524e-01,  7.0439e-02, -7.3086e-02,\n",
      "          2.3546e-02, -5.5191e-02,  3.9033e-02,  8.8104e-03, -2.9507e-02,\n",
      "         -7.2770e-02, -4.9728e-02,  1.3002e-02,  6.9008e-02,  5.5263e-03,\n",
      "         -1.0071e-02, -1.3874e-02, -4.7808e-03,  6.3247e-02,  9.0635e-02,\n",
      "         -6.8301e-02,  2.5529e-02, -1.0687e-01, -4.4864e-02,  1.5604e-02,\n",
      "         -9.5490e-03,  5.4705e-02,  3.8651e-02,  2.3330e-02, -5.4452e-02,\n",
      "         -3.3616e-02,  2.2151e-02, -5.0358e-03,  1.1959e-02, -5.4787e-02,\n",
      "         -1.9210e-02,  1.0959e-01,  6.9989e-02, -3.0550e-02,  1.0524e-01,\n",
      "          1.7950e-02, -1.5250e-02,  6.7686e-02,  1.2116e-01, -2.9072e-02,\n",
      "          7.7559e-02, -7.0317e-02,  4.3403e-02,  7.9936e-02, -6.5485e-02,\n",
      "         -4.2324e-02, -3.3591e-02, -7.2292e-02, -2.4866e-02,  6.1592e-02,\n",
      "         -2.2260e-02,  9.9320e-02,  2.6262e-02,  1.0002e-01, -4.1924e-02,\n",
      "          4.2741e-03, -1.6355e-03, -7.0960e-02, -5.0664e-02,  1.9741e-02,\n",
      "          6.3409e-03,  3.0713e-02, -3.5109e-33, -9.4917e-03,  2.6203e-02,\n",
      "          8.0580e-02,  1.1620e-01, -8.0777e-02,  1.3383e-02, -4.5946e-02,\n",
      "         -5.0623e-03, -1.3827e-01, -5.1174e-02,  2.4824e-02, -4.8660e-02,\n",
      "         -8.9825e-03, -4.2390e-02, -1.8331e-02,  8.9157e-02,  5.5890e-02,\n",
      "          2.3302e-02,  3.2743e-03,  8.0012e-02,  3.7409e-02, -1.0368e-01,\n",
      "         -2.1190e-02, -1.7754e-02,  2.5649e-02, -2.7085e-02,  5.2619e-02,\n",
      "         -1.2606e-01,  5.8795e-02,  8.2107e-03,  6.0940e-02,  5.0960e-02,\n",
      "         -2.7004e-02, -4.4966e-02,  2.5681e-02,  6.1759e-02, -1.7749e-02,\n",
      "         -7.9805e-02, -2.9433e-02,  1.6121e-02,  2.2461e-02, -3.1851e-02,\n",
      "         -2.1836e-02, -1.9096e-02,  6.3051e-02, -1.5681e-02,  7.6319e-02,\n",
      "         -4.2225e-02,  9.7061e-02, -7.4342e-03, -6.3810e-02, -8.3778e-02,\n",
      "         -9.9924e-02,  7.6835e-02, -5.9675e-02,  6.8065e-02,  3.6408e-02,\n",
      "          1.9104e-02, -5.2349e-02, -4.6449e-02, -7.8133e-02,  3.7892e-02,\n",
      "         -5.4399e-02,  6.5050e-02,  1.3699e-02, -6.5796e-02,  2.7329e-02,\n",
      "         -3.4004e-02,  4.3907e-02, -6.9335e-02, -1.2360e-02, -3.1176e-02,\n",
      "          6.8478e-02,  8.7932e-02, -3.6541e-03,  9.4832e-02, -2.6814e-02,\n",
      "          3.5199e-02, -1.3790e-02,  4.7004e-02, -4.2243e-02,  5.0714e-02,\n",
      "         -4.0082e-02,  5.4303e-03,  1.1821e-01, -1.0161e-02, -3.0917e-02,\n",
      "         -1.7329e-02, -6.6611e-02, -7.0589e-04, -3.3058e-02,  3.5975e-02,\n",
      "          1.2024e-02, -6.2227e-03, -5.6630e-02,  6.9684e-34, -1.4312e-02,\n",
      "         -9.8497e-02,  5.1574e-02,  3.4089e-02,  4.7976e-02, -5.8215e-02,\n",
      "          3.2499e-02,  1.3897e-01, -1.2387e-02,  9.0754e-03, -4.1116e-02,\n",
      "         -5.1235e-02,  6.1794e-02, -5.9722e-03,  1.9835e-02,  3.5728e-02,\n",
      "         -1.0825e-02,  4.8801e-02, -3.4452e-02, -5.0191e-02, -3.0954e-02,\n",
      "          2.5682e-02, -7.6494e-02,  2.2805e-02, -3.4306e-03, -7.2608e-02,\n",
      "          5.1100e-02,  5.4550e-02, -4.3516e-02,  4.5979e-03, -3.3518e-02,\n",
      "          7.3775e-03, -2.0520e-01, -1.1854e-02, -2.8598e-02, -2.7854e-02,\n",
      "         -4.8456e-02, -4.4998e-02,  7.9161e-03, -1.8392e-02, -8.0965e-02,\n",
      "         -7.3153e-03,  1.7060e-03, -1.3040e-02,  1.0081e-02, -9.5932e-02,\n",
      "          2.3629e-02, -2.5238e-02,  2.6658e-02, -1.5607e-02,  1.9018e-02,\n",
      "          9.0900e-03, -3.6340e-02, -1.6240e-02,  7.6395e-03,  1.5891e-02,\n",
      "          9.4523e-02, -8.0931e-02, -1.5133e-02,  4.3945e-02, -2.9881e-02,\n",
      "          6.5171e-02,  4.0115e-02,  9.7704e-02,  4.4183e-02, -4.9112e-02,\n",
      "         -7.7046e-02, -1.2634e-02, -1.5550e-02, -4.7696e-02,  4.5433e-02,\n",
      "          4.4270e-03,  1.4690e-02,  1.2563e-02,  4.3614e-02,  2.1227e-02,\n",
      "          6.6362e-02,  1.1333e-01,  2.2424e-02,  3.7768e-02,  1.2362e-02,\n",
      "          2.6583e-02, -2.1462e-02,  1.1271e-02, -1.7596e-02, -2.8037e-02,\n",
      "          3.9713e-03, -4.1181e-02,  3.3958e-02,  1.1167e-02, -3.2049e-02,\n",
      "          7.9933e-02,  1.3886e-02, -8.0291e-02, -2.8934e-02, -1.9202e-08,\n",
      "         -6.6829e-02,  1.7477e-02,  2.6720e-02,  1.5781e-02, -3.1238e-03,\n",
      "          4.8631e-02, -3.5977e-02, -1.8446e-02,  6.1989e-03, -5.9335e-02,\n",
      "         -3.8284e-02,  5.2684e-02,  4.2426e-03, -1.8917e-02,  2.1841e-02,\n",
      "         -2.7126e-02,  7.4408e-02,  3.5710e-02, -1.1994e-03,  7.4031e-02,\n",
      "          7.7127e-03, -1.6716e-03, -1.8253e-02,  2.7859e-02,  8.5915e-03,\n",
      "          7.8143e-03,  1.2183e-01,  4.9335e-02, -2.3253e-02, -5.4606e-02,\n",
      "         -7.2928e-02,  7.1939e-02,  1.5539e-02,  4.8002e-02, -3.3544e-03,\n",
      "         -4.1128e-02, -1.3474e-01, -3.0871e-02, -4.8017e-02,  6.6204e-03,\n",
      "          3.7088e-02,  4.6157e-02,  3.3752e-02, -8.2946e-03, -5.6010e-02,\n",
      "          5.7621e-02, -7.5969e-03, -1.0978e-01, -2.7847e-02,  3.6299e-02,\n",
      "         -4.7659e-02,  1.4003e-02,  6.3604e-02, -2.3765e-02,  1.2774e-02,\n",
      "         -1.7957e-02,  6.0589e-02,  4.1273e-02,  4.3481e-02,  3.5323e-02,\n",
      "          7.6870e-02, -4.4595e-02, -6.9648e-02,  8.5320e-03]])\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"My name is Philipp and I live in Germany.\", padding=True, truncation=True, return_tensors='pt')\n",
    "pred = model(**encoded_input)\n",
    "sentence_embeddings = sentence_embeddings = mean_pooling(pred, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "print(sentence_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open(\"/home/humza/Downloads/projects/genml/data/faiss/training_data.json\", \"r\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(196, 768)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 12, 384)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 350/350 [00:00<00:00, 147kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:05<00:00, 41.1kB/s] \n",
      "Downloading: 100%|██████████| 455k/455k [00:07<00:00, 63.1kB/s] \n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 57.1kB/s]\n",
      "Downloading: 100%|██████████| 612/612 [00:00<00:00, 628kB/s]\n",
      "Downloading: 100%|██████████| 86.7M/86.7M [01:43<00:00, 882kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 6.7657e-02,  6.3496e-02,  4.8713e-02,  7.9305e-02,  3.7448e-02,\n",
      "          2.6528e-03,  3.9375e-02, -7.0985e-03,  5.9361e-02,  3.1537e-02,\n",
      "          6.0098e-02, -5.2905e-02,  4.0607e-02, -2.5931e-02,  2.9843e-02,\n",
      "          1.1269e-03,  7.3515e-02, -5.0382e-02, -1.2239e-01,  2.3703e-02,\n",
      "          2.9727e-02,  4.2477e-02,  2.5634e-02,  1.9952e-03, -5.6919e-02,\n",
      "         -2.7160e-02, -3.2904e-02,  6.6025e-02,  1.1901e-01, -4.5879e-02,\n",
      "         -7.2621e-02, -3.2584e-02,  5.2341e-02,  4.5055e-02,  8.2531e-03,\n",
      "          3.6702e-02, -1.3942e-02,  6.5392e-02, -2.6427e-02,  2.0641e-04,\n",
      "         -1.3664e-02, -3.6281e-02, -1.9504e-02, -2.8974e-02,  3.9427e-02,\n",
      "         -8.8409e-02,  2.6243e-03,  1.3671e-02,  4.8306e-02, -3.1157e-02,\n",
      "         -1.1733e-01, -5.1169e-02, -8.8529e-02, -2.1896e-02,  1.4299e-02,\n",
      "          4.4417e-02, -1.3482e-02,  7.4339e-02,  2.6638e-02, -1.9876e-02,\n",
      "          1.7919e-02, -1.0605e-02, -9.0426e-02,  2.1327e-02,  1.4120e-01,\n",
      "         -6.4717e-03, -1.4038e-03, -1.5361e-02, -8.7357e-02,  7.2217e-02,\n",
      "          2.0140e-02,  4.2559e-02, -3.4901e-02,  3.1951e-04, -8.0297e-02,\n",
      "         -3.2747e-02,  2.8527e-02, -5.1366e-02,  1.0939e-01,  8.1933e-02,\n",
      "         -9.8404e-02, -9.3410e-02, -1.5129e-02,  4.5125e-02,  4.9417e-02,\n",
      "         -2.5187e-02,  1.5708e-02, -1.2929e-01,  5.3189e-03,  4.0234e-03,\n",
      "         -2.3457e-02, -6.7298e-02,  2.9228e-02, -2.6085e-02,  1.3063e-02,\n",
      "         -3.1166e-02, -4.8271e-02, -5.5886e-02, -3.8750e-02,  1.2001e-01,\n",
      "         -1.0392e-02,  4.8970e-02,  5.5354e-02,  4.4936e-02, -4.0098e-03,\n",
      "         -1.0296e-01, -2.9297e-02, -5.8340e-02,  2.7047e-02, -2.2017e-02,\n",
      "         -7.2224e-02, -4.1387e-02, -1.9330e-02,  2.7333e-03,  2.7700e-04,\n",
      "         -9.6759e-02, -1.0057e-01, -1.4192e-02, -8.0789e-02,  4.5392e-02,\n",
      "          2.4504e-02,  5.9761e-02, -7.3818e-02,  1.1984e-02, -6.6340e-02,\n",
      "         -7.6905e-02,  3.8516e-02, -5.5936e-33,  2.8001e-02, -5.6078e-02,\n",
      "         -4.8660e-02,  2.1557e-02,  6.0198e-02, -4.8140e-02, -3.5025e-02,\n",
      "          1.9331e-02, -1.7515e-02, -3.8921e-02, -3.8107e-03, -1.7029e-02,\n",
      "          2.8210e-02,  1.2829e-02,  4.7160e-02,  6.2103e-02, -6.4359e-02,\n",
      "          1.2929e-01, -1.3123e-02,  5.2307e-02, -3.7368e-02,  2.8909e-02,\n",
      "         -1.6898e-02, -2.3733e-02, -3.3349e-02, -5.1676e-02,  1.5536e-02,\n",
      "          2.0880e-02, -1.2537e-02,  4.5958e-02,  3.7272e-02,  2.8057e-02,\n",
      "         -5.9001e-02, -1.1699e-02,  4.9218e-02,  4.7033e-02,  7.3549e-02,\n",
      "         -3.7053e-02,  3.9846e-03,  1.0641e-02, -1.6148e-04, -5.2717e-02,\n",
      "          2.7593e-02, -3.9292e-02,  8.4472e-02,  4.8686e-02, -4.8587e-03,\n",
      "          1.7995e-02, -4.2857e-02,  1.2338e-02,  6.3995e-03,  4.0482e-02,\n",
      "          1.4889e-02, -1.5394e-02,  7.6295e-02,  2.3704e-02,  4.4524e-02,\n",
      "          5.0820e-02, -2.3125e-03, -1.8874e-02, -1.2334e-02,  4.6600e-02,\n",
      "         -5.6344e-02,  6.2993e-02, -3.1554e-02,  3.2491e-02,  2.3467e-02,\n",
      "         -6.5544e-02,  2.0171e-02,  2.5708e-02, -1.2387e-02, -8.3649e-03,\n",
      "         -6.6438e-02,  9.4307e-02, -3.5709e-02, -3.4248e-02, -6.6636e-03,\n",
      "         -8.0153e-03, -3.0971e-02,  4.3301e-02, -8.2140e-03, -1.5079e-01,\n",
      "          3.0769e-02,  4.0072e-02, -3.7929e-02,  1.9322e-03,  4.0053e-02,\n",
      "         -8.7708e-02, -3.6849e-02,  8.5796e-03, -3.1925e-02, -1.2526e-02,\n",
      "          7.3554e-02,  1.3473e-03,  2.0592e-02,  2.7110e-33, -5.1858e-02,\n",
      "          5.7836e-02, -9.1898e-02,  3.9442e-02,  1.0558e-01, -1.9691e-02,\n",
      "          6.1840e-02, -7.6347e-02,  2.4088e-02,  9.4005e-02, -1.1654e-01,\n",
      "          3.7120e-02,  5.2243e-02, -3.9586e-03,  5.7221e-02,  5.3285e-03,\n",
      "          1.2402e-01,  1.3902e-02, -1.1025e-02,  3.5605e-02, -3.3075e-02,\n",
      "          8.1657e-02, -1.5200e-02,  6.0559e-02, -6.0140e-02,  3.2610e-02,\n",
      "         -3.4830e-02, -1.6988e-02, -9.7491e-02, -2.7148e-02,  1.7471e-03,\n",
      "         -7.6898e-02, -4.3186e-02, -1.8998e-02, -2.9166e-02,  5.7749e-02,\n",
      "          2.4182e-02, -1.1690e-02, -6.2144e-02,  2.8435e-02, -2.3752e-04,\n",
      "         -2.5178e-02,  4.3964e-03,  8.1284e-02,  3.6418e-02, -6.0401e-02,\n",
      "         -3.6552e-02, -7.9375e-02, -5.0853e-03,  6.6970e-02, -1.1778e-01,\n",
      "          3.2374e-02, -4.7125e-02, -1.3446e-02, -9.4844e-02,  8.2496e-03,\n",
      "         -1.0675e-02, -6.8188e-02,  1.1182e-03,  2.4802e-02, -6.3589e-02,\n",
      "          2.8449e-02, -2.6130e-02,  8.5811e-02,  1.1468e-01, -5.3535e-02,\n",
      "         -5.6359e-02,  4.2601e-02,  1.0945e-02,  2.0958e-02,  1.0013e-01,\n",
      "          3.2605e-02, -1.8421e-01, -3.9321e-02, -6.9145e-02, -6.3810e-02,\n",
      "         -6.5639e-02, -6.4125e-03, -4.7961e-02, -7.6813e-02,  2.9538e-02,\n",
      "         -2.2995e-02,  4.1704e-02, -2.5005e-02, -4.5450e-03, -4.1714e-02,\n",
      "         -1.3229e-02, -6.3836e-02, -2.4647e-03, -1.3734e-02,  1.6898e-02,\n",
      "         -6.3040e-02,  8.9888e-02,  4.1817e-02, -1.8569e-02, -1.8044e-08,\n",
      "         -1.6800e-02, -3.2158e-02,  6.3038e-02, -4.1309e-02,  4.4482e-02,\n",
      "          2.0246e-03,  6.2959e-02, -5.1737e-03, -1.0044e-02, -3.0564e-02,\n",
      "          3.5267e-02,  5.5858e-02, -4.6712e-02,  3.4510e-02,  3.2958e-02,\n",
      "          4.3011e-02,  2.9436e-02, -3.0316e-02, -1.7111e-02,  7.3748e-02,\n",
      "         -5.4791e-02,  2.7752e-02,  6.2017e-03,  1.5880e-02,  3.4298e-02,\n",
      "         -5.1575e-03,  2.3508e-02,  7.5314e-02,  1.9284e-02,  3.3620e-02,\n",
      "          5.0910e-02,  1.5250e-01,  1.6421e-02,  2.7053e-02,  3.7516e-02,\n",
      "          2.1855e-02,  5.6633e-02, -3.9575e-02,  7.1231e-02, -5.4138e-02,\n",
      "          1.0376e-03,  2.1185e-02, -3.5631e-02,  1.0902e-01,  2.7653e-03,\n",
      "          3.1400e-02,  1.3842e-03, -3.4574e-02, -4.5928e-02,  2.8808e-02,\n",
      "          7.1690e-03,  4.8469e-02,  2.6102e-02, -9.4407e-03,  2.8217e-02,\n",
      "          3.4872e-02,  3.6910e-02, -8.5895e-03, -3.5321e-02, -2.4786e-02,\n",
      "         -1.9192e-02,  3.8071e-02,  5.9965e-02, -4.2229e-02],\n",
      "        [ 8.6439e-02,  1.0276e-01,  5.3946e-03,  2.0445e-03, -9.9633e-03,\n",
      "          2.5385e-02,  4.9288e-02, -3.0627e-02,  6.8725e-02,  1.0137e-02,\n",
      "          7.7540e-02, -9.0081e-02,  6.1062e-03, -5.6990e-02,  1.4171e-02,\n",
      "          2.8049e-02, -8.6846e-02,  7.6440e-02, -1.0349e-01, -6.7744e-02,\n",
      "          6.9995e-02,  8.4425e-02, -7.2491e-03,  1.0477e-02,  1.3402e-02,\n",
      "          6.7758e-02, -9.4209e-02, -3.7169e-02,  5.2262e-02, -3.1085e-02,\n",
      "         -9.6341e-02,  1.5772e-02,  2.5787e-02,  7.8525e-02,  7.8995e-02,\n",
      "          1.9152e-02,  1.6436e-02,  3.1009e-03,  3.8131e-02,  2.3709e-02,\n",
      "          1.0539e-02, -4.4064e-02,  4.4174e-02, -2.5873e-02,  6.1538e-02,\n",
      "         -4.0543e-02, -8.6414e-02,  3.1972e-02, -8.9065e-04, -2.4444e-02,\n",
      "         -9.1972e-02,  2.3394e-02, -8.3029e-02,  4.4151e-02, -2.4969e-02,\n",
      "          6.2302e-02, -1.3035e-03,  7.5140e-02,  2.4639e-02, -6.4724e-02,\n",
      "         -1.1773e-01,  3.8339e-02, -9.1177e-02,  6.3545e-02,  7.6274e-02,\n",
      "         -8.8024e-02,  9.5456e-03, -4.6972e-02, -8.4174e-02,  3.8882e-02,\n",
      "         -1.1439e-01,  6.2886e-03, -3.4936e-02,  2.3975e-02, -3.3132e-02,\n",
      "         -1.5724e-02, -3.7896e-02, -8.8125e-03,  7.0612e-02,  3.2807e-02,\n",
      "          2.0367e-03, -1.1228e-01,  6.7972e-03,  1.2277e-02,  3.3530e-02,\n",
      "         -1.3620e-02, -2.2549e-02, -2.2523e-02, -2.0319e-02,  5.0430e-02,\n",
      "         -7.4865e-02, -8.2282e-02,  7.6596e-02,  4.9339e-02, -3.7555e-02,\n",
      "          1.4463e-02, -5.7246e-02, -1.7995e-02,  1.0970e-01,  1.1946e-01,\n",
      "          8.0925e-04,  6.1706e-02,  3.2632e-02, -1.3078e-01, -1.4864e-01,\n",
      "         -6.1623e-02,  4.3389e-02,  2.6713e-02,  1.3979e-02, -3.9400e-02,\n",
      "         -2.5271e-02,  3.8774e-03,  3.5866e-02, -6.1542e-02,  3.7666e-02,\n",
      "          2.6757e-02, -3.8266e-02, -3.5479e-02, -2.3923e-02,  8.6798e-02,\n",
      "         -1.8406e-02,  7.7104e-02,  1.3987e-03,  7.0038e-02, -4.7788e-02,\n",
      "         -7.8982e-02,  5.1081e-02, -2.9987e-33, -3.9165e-02, -2.5621e-03,\n",
      "          1.6521e-02,  9.4894e-03, -5.6622e-02,  6.5778e-02, -4.7700e-02,\n",
      "          1.1166e-02, -5.7356e-02, -9.1626e-03, -2.1752e-02, -5.5953e-02,\n",
      "         -1.1142e-02,  9.3279e-02,  1.6677e-02, -1.3672e-02,  4.3439e-02,\n",
      "          1.8724e-03,  7.2995e-03,  5.1633e-02,  4.8061e-02,  1.3534e-01,\n",
      "         -1.7174e-02, -1.2970e-02, -7.5011e-02,  2.6111e-02,  2.6980e-02,\n",
      "          7.8306e-04, -4.8727e-02,  1.1784e-02, -4.5958e-02, -4.8321e-02,\n",
      "         -1.9567e-02,  1.9389e-02,  1.9881e-02,  1.6743e-02,  9.8780e-02,\n",
      "         -2.7409e-02,  2.3481e-02,  3.7023e-03, -6.1451e-02, -1.2123e-03,\n",
      "         -9.5047e-03,  9.2515e-03,  2.3844e-02,  8.6123e-02,  2.2679e-02,\n",
      "          5.4512e-04,  3.4713e-02,  6.2546e-03, -6.9278e-03,  3.9240e-02,\n",
      "          1.1567e-02,  3.2628e-02,  6.2216e-02,  2.7611e-02,  1.8688e-02,\n",
      "          3.5581e-02,  4.1180e-02,  1.5478e-02,  4.2269e-02,  3.8225e-02,\n",
      "          1.0031e-02, -2.8325e-02,  4.4705e-02, -4.1046e-02, -4.5055e-03,\n",
      "         -5.4473e-02,  2.6232e-02,  1.7986e-02, -1.2312e-01, -4.6695e-02,\n",
      "         -1.3591e-02,  6.4671e-02,  3.5735e-03, -1.2223e-02, -1.7938e-02,\n",
      "         -2.5550e-02,  2.3722e-02,  4.0866e-03, -6.5148e-02,  4.4365e-02,\n",
      "          4.6860e-02, -3.2517e-02,  4.0226e-03, -3.9761e-03,  1.1194e-02,\n",
      "         -9.9560e-02,  3.3317e-02,  8.0106e-02,  9.4269e-02, -6.3829e-02,\n",
      "          3.2315e-02, -5.1355e-02, -7.4988e-03,  5.3005e-34, -4.1320e-02,\n",
      "          9.4965e-02, -1.0640e-01,  4.9659e-02, -3.4191e-02, -3.1675e-02,\n",
      "         -1.7156e-02,  1.7010e-03,  5.7976e-02, -1.2178e-03, -1.6854e-02,\n",
      "         -5.1691e-02,  5.5300e-02, -3.4265e-02,  3.0818e-02, -3.1048e-02,\n",
      "          9.2753e-02,  3.7266e-02, -2.3740e-02,  4.4589e-02,  1.4615e-02,\n",
      "          1.1624e-01, -5.0011e-02,  3.8872e-02,  4.2474e-03,  2.5698e-02,\n",
      "          3.2724e-02,  4.2991e-02, -1.3614e-02,  2.5612e-02,  1.0626e-02,\n",
      "         -8.4686e-02, -9.5298e-02,  1.0840e-01, -7.5160e-02, -1.3777e-02,\n",
      "          6.3734e-02, -4.4967e-03, -3.2532e-02,  6.2361e-02,  3.4805e-02,\n",
      "         -3.5492e-02, -2.0022e-02,  3.6661e-02, -2.4884e-02,  1.0182e-02,\n",
      "         -7.0123e-02, -4.3195e-02,  2.9533e-02, -2.9490e-04, -3.4539e-02,\n",
      "          1.4668e-02, -9.8397e-02, -4.7049e-02, -8.8550e-03, -8.8991e-02,\n",
      "          3.5100e-02, -1.2960e-01, -4.9887e-02, -6.1205e-02, -5.9780e-02,\n",
      "          9.4632e-03,  4.9122e-02, -7.7503e-02,  8.0973e-02, -4.7926e-02,\n",
      "          2.3438e-03,  7.5703e-02, -2.4018e-02, -1.5255e-02,  4.8674e-02,\n",
      "         -3.8597e-02, -7.0483e-02, -1.2035e-02, -3.8879e-02, -7.7602e-02,\n",
      "         -1.0724e-02,  1.0419e-02, -2.1375e-02, -9.1739e-02, -1.1134e-02,\n",
      "         -2.9607e-02,  2.4646e-02,  4.6571e-03, -1.6345e-02, -3.9522e-02,\n",
      "          7.7337e-02, -2.8473e-02, -3.6994e-03,  8.2767e-02, -1.1041e-02,\n",
      "          3.1398e-02,  5.3509e-02,  5.7515e-02, -3.1762e-02, -1.5291e-08,\n",
      "         -7.9966e-02, -4.7680e-02, -8.5979e-02,  5.6962e-02, -4.0887e-02,\n",
      "          2.2383e-02, -4.6445e-03, -3.8013e-02, -3.1067e-02, -1.0728e-02,\n",
      "          1.9770e-02,  7.7700e-03, -6.0947e-03, -3.8638e-02,  2.8027e-02,\n",
      "          6.7814e-02, -2.3535e-02,  3.2175e-02,  8.0254e-03, -2.3911e-02,\n",
      "         -1.2200e-03,  3.1460e-02, -5.2492e-02, -8.0682e-03,  3.1478e-03,\n",
      "          5.1150e-02, -4.4410e-02,  6.3601e-02,  3.8508e-02,  3.3043e-02,\n",
      "         -4.1873e-03,  4.9559e-02, -5.6961e-02, -6.4971e-03, -2.4979e-02,\n",
      "         -1.6087e-02,  6.6229e-02, -2.0631e-02,  1.0805e-01,  1.6855e-02,\n",
      "          1.4381e-02, -1.3213e-02, -1.2939e-01,  6.9522e-02, -5.5577e-02,\n",
      "         -6.7541e-02, -5.4582e-03, -6.1359e-03,  3.9084e-02, -6.2878e-02,\n",
      "          3.7406e-02, -1.1657e-02,  1.2915e-02, -5.5250e-02,  5.1608e-02,\n",
      "         -4.3084e-03,  5.8025e-02,  1.8694e-02,  2.2781e-02,  3.2167e-02,\n",
      "          5.3798e-02,  7.0285e-02,  7.4931e-02, -8.4178e-02]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\r\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 365 kB 482 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting multiprocess\r\n",
      "  Downloading multiprocess-0.70.13-py39-none-any.whl (132 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 132 kB 7.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: packaging in /home/humza/miniconda3/lib/python3.9/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from datasets) (2.27.1)\r\n",
      "Requirement already satisfied: pandas in /home/humza/miniconda3/lib/python3.9/site-packages (from datasets) (1.4.3)\r\n",
      "Collecting fsspec[http]>=2021.11.1\r\n",
      "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 141 kB 7.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /home/humza/miniconda3/lib/python3.9/site-packages (from datasets) (1.23.1)\r\n",
      "Collecting xxhash\r\n",
      "  Downloading xxhash-3.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 211 kB 7.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting pyarrow>=6.0.0\r\n",
      "  Downloading pyarrow-9.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 35.3 MB 295 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.62.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from datasets) (4.63.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from datasets) (0.7.0)\r\n",
      "Collecting responses<0.19\r\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\r\n",
      "Requirement already satisfied: dill<0.3.6 in /home/humza/miniconda3/lib/python3.9/site-packages (from datasets) (0.3.5.1)\r\n",
      "Collecting aiohttp\r\n",
      "  Downloading aiohttp-3.8.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.2 MB 253 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.3.0)\r\n",
      "Requirement already satisfied: filelock in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/humza/miniconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.8)\r\n",
      "Collecting aiosignal>=1.1.2\r\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\r\n",
      "Collecting frozenlist>=1.1.1\r\n",
      "  Downloading frozenlist-1.3.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 158 kB 286 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: attrs>=17.3.0 in /home/humza/miniconda3/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\r\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\r\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\r\n",
      "Collecting multidict<7.0,>=4.5\r\n",
      "  Downloading multidict-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 114 kB 154 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting yarl<2.0,>=1.0\r\n",
      "  Downloading yarl-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 264 kB 151 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/humza/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/humza/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, pyarrow, multiprocess, datasets\r\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 datasets-2.4.0 frozenlist-1.3.1 fsspec-2022.7.1 multidict-6.0.2 multiprocess-0.70.13 pyarrow-9.0.0 responses-0.18.0 xxhash-3.0.0 yarl-1.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unknown task: feature-extraction. Possible values are [<class 'transformers.models.auto.modeling_auto.AutoModel'>, <class 'transformers.models.auto.modeling_auto.AutoModelForMaskedLM'>, <class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_auto.AutoModelForTokenClassification'>, <class 'transformers.models.auto.modeling_auto.AutoModelForMultipleChoice'>, <class 'transformers.models.auto.modeling_auto.AutoModelForQuestionAnswering'>, <class 'transformers.models.auto.modeling_auto.AutoModelForImageClassification'>, <class 'transformers.models.auto.modeling_auto.AutoModelForMaskedImageModeling'>]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m task \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature-extraction\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# create ORTOptimizer and define optimization configuration\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mORTOptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m optimization_config \u001B[38;5;241m=\u001B[39m OptimizationConfig(optimization_level\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m99\u001B[39m) \u001B[38;5;66;03m# enable all optimizations\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# apply the optimization configuration to the model\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/optimum/onnxruntime/optimization.py:60\u001B[0m, in \u001B[0;36mORTOptimizer.from_pretrained\u001B[0;34m(model_name_or_path, feature, opset)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;124;03mInstantiate a `ORTOptimizer` from a pretrained pytorch model and preprocessor.\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03m    An instance of `ORTOptimizer`.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     59\u001B[0m preprocessor \u001B[38;5;241m=\u001B[39m get_preprocessor(model_name_or_path)\n\u001B[0;32m---> 60\u001B[0m model_class \u001B[38;5;241m=\u001B[39m \u001B[43mFeaturesManager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_model_class_for_feature\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name_or_path)\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ORTOptimizer(preprocessor, model, feature, opset)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/onnx/features.py:468\u001B[0m, in \u001B[0;36mFeaturesManager.get_model_class_for_feature\u001B[0;34m(feature, framework)\u001B[0m\n\u001B[1;32m    466\u001B[0m     task_to_automodel \u001B[38;5;241m=\u001B[39m FeaturesManager\u001B[38;5;241m.\u001B[39m_TASKS_TO_TF_AUTOMODELS\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m task_to_automodel:\n\u001B[0;32m--> 468\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[1;32m    469\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown task: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Possible values are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(FeaturesManager\u001B[38;5;241m.\u001B[39m_TASKS_TO_AUTOMODELS\u001B[38;5;241m.\u001B[39mvalues())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    470\u001B[0m     )\n\u001B[1;32m    471\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m task_to_automodel[task]\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Unknown task: feature-extraction. Possible values are [<class 'transformers.models.auto.modeling_auto.AutoModel'>, <class 'transformers.models.auto.modeling_auto.AutoModelForMaskedLM'>, <class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_auto.AutoModelForTokenClassification'>, <class 'transformers.models.auto.modeling_auto.AutoModelForMultipleChoice'>, <class 'transformers.models.auto.modeling_auto.AutoModelForQuestionAnswering'>, <class 'transformers.models.auto.modeling_auto.AutoModelForImageClassification'>, <class 'transformers.models.auto.modeling_auto.AutoModelForMaskedImageModeling'>]\""
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from optimum.onnxruntime import ORTOptimizer\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig\n",
    "\n",
    "model_id = \"microsoft/codebert-base\"\n",
    "onnx_path = Path(\"onnx\")\n",
    "\n",
    "task = \"feature-extraction\"\n",
    "# create ORTOptimizer and define optimization configuration\n",
    "optimizer = ORTOptimizer.from_pretrained(model_id, feature=task)\n",
    "optimization_config = OptimizationConfig(optimization_level=99) # enable all optimizations\n",
    "\n",
    "# apply the optimization configuration to the model\n",
    "optimizer.export(\n",
    "    onnx_model_path=onnx_path / \"model.onnx\",\n",
    "    onnx_optimized_model_output_path=onnx_path / \"model-optimized.onnx\",\n",
    "    optimization_config=optimization_config,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "prediction = optimum_feature_extractor(\"What's my name?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFDPyxIUErpn",
    "outputId": "e96bfc46-3d23-4892-9f25-4d98c8f8e613",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 131 ms, sys: 2.26 ms, total: 133 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question Answering"
   ],
   "metadata": {
    "id": "kpc7mDGUixqu",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Base Model"
   ],
   "metadata": {
    "id": "kBmUbLOqi249",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"deepset/roberta-base-squad2\"\n",
    "task = \"question-answering\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# test the model with using transformers pipeline, with handle_impossible_answer for squad_v2 \n",
    "qa_model = pipeline(task, model=model_id, tokenizer=tokenizer, handle_impossible_answer=True)"
   ],
   "metadata": {
    "id": "p9teFEo8jEWI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 79.0/79.0 [00:00<00:00, 33.7kB/s]\n",
      "Downloading config.json: 100%|██████████| 571/571 [00:00<00:00, 268kB/s]\n",
      "Downloading vocab.json: 100%|██████████| 878k/878k [00:05<00:00, 166kB/s]  \n",
      "Downloading merges.txt: 100%|██████████| 446k/446k [00:10<00:00, 42.4kB/s] \n",
      "Downloading special_tokens_map.json: 100%|██████████| 772/772 [00:00<00:00, 293kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 473M/473M [06:57<00:00, 1.19MB/s] \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "prediction = qa_model(question=\"what is my name?\", context=\"My name is Humza and I'm 5 years old\")\n",
    "print(prediction)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GHeXzSGHjEgX",
    "outputId": "757ada32-1e76-4fd9-d6fe-f869837bd135",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6795036196708679, 'start': 11, 'end': 16, 'answer': 'Humza'}\n",
      "CPU times: user 2.66 s, sys: 0 ns, total: 2.66 s\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimized Model"
   ],
   "metadata": {
    "id": "RTmS1nUsi59B",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
    "\n",
    "model_id = \"deepset/roberta-base-squad2\"\n",
    "onnx_path = Path(\"onnx_qa\")\n",
    "task = \"question-answering\"\n",
    "\n",
    "# load vanilla transformers and convert to onnx\n",
    "model = ORTModelForQuestionAnswering.from_pretrained(model_id, from_transformers=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# save onnx checkpoint and tokenizer\n",
    "model.save_pretrained(onnx_path)\n",
    "tokenizer.save_pretrained(onnx_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "94ccc999334044cdbd502d5c5cf021bf",
      "18ba8f1c9abd448b99935ce008c00c23",
      "78b99f15dbce47cb9aaf92c6b891b4d7",
      "c8d23799f62b4cb2915c94b86332bf68",
      "a9a885bc5b7e49778fc19675ed71cf58",
      "c10a910ceb074e24aff32369f64f5155",
      "9a8544fb1e124d0f8a66cb98cc174a15",
      "5f2dad47f9da481cb185feab60ab4e06",
      "51fdd1c8de3f491ea8f86cc86665ff5d",
      "4854182869074745873f5d7f4a0d961c",
      "8cde3c6bd0f44f6bbc1ec247925af7e2"
     ]
    },
    "id": "_a9vdsBOq_dC",
    "outputId": "32160fba-cc9d-4bb4-abe3-638f80a0bdc2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 571/571 [00:00<00:00, 32.5kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "('onnx_qa/tokenizer_config.json',\n 'onnx_qa/special_tokens_map.json',\n 'onnx_qa/vocab.json',\n 'onnx_qa/merges.txt',\n 'onnx_qa/added_tokens.json',\n 'onnx_qa/tokenizer.json')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from optimum.onnxruntime import ORTOptimizer\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig\n",
    "\n",
    "# create ORTOptimizer and define optimization configuration\n",
    "optimizer = ORTOptimizer.from_pretrained(model_id, feature=task)\n",
    "optimization_config = OptimizationConfig(optimization_level=99) # enable all optimizations\n",
    "\n",
    "# apply the optimization configuration to the model\n",
    "optimizer.export(\n",
    "    onnx_model_path=onnx_path / \"model.onnx\",\n",
    "    onnx_optimized_model_output_path=onnx_path / \"model-optimized.onnx\",\n",
    "    optimization_config=optimization_config,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bGiO42yrS2g",
    "outputId": "74497b0d-ccaa-4673-dce9-d97a5eee619c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import optimum.onnxruntime.optimization because of the following error (look up to see its traceback):\nNo module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1002\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1001\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1002\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1003\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/importlib/__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:986\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:680\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:850\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:228\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/optimum/onnxruntime/optimization.py:29\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01monnxruntime\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_fusion_statistics, optimize_model\n\u001B[0;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfiguration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OptimizationConfig\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ORTConfigManager\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/optimum/onnxruntime/configuration.py:20\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dict, List, Optional, Tuple, Union\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Version, parse\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'datasets'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01moptimum\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnxruntime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ORTOptimizer\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01moptimum\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnxruntime\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfiguration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OptimizationConfig\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# create ORTOptimizer and define optimization configuration\u001B[39;00m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1055\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:992\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    990\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[1;32m    991\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m--> 992\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    993\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m    994\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1004\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1002\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m   1003\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1004\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1005\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1006\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1007\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to import optimum.onnxruntime.optimization because of the following error (look up to see its traceback):\nNo module named 'datasets'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
    "\n",
    "# load quantized model\n",
    "opt_model = ORTModelForQuestionAnswering.from_pretrained(onnx_path, file_name=\"model-optimized.onnx\")\n",
    "\n",
    "# test the quantized model with using transformers pipeline\n",
    "optimum_qa_model = pipeline(task, model=opt_model, tokenizer=tokenizer, handle_impossible_answer=True)"
   ],
   "metadata": {
    "id": "A6nAxzm3rXe4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "prediction = optimum_qa_model(question=\"what is my name?\", context=\"My name is Humza and I'm 5 years old\")\n",
    "print(prediction)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9C0_GQYdjFhk",
    "outputId": "574a1ece-e289-428b-aced-72837fa4acbf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantized Model"
   ],
   "metadata": {
    "id": "C3-SnFQBi_MS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from optimum.onnxruntime import ORTQuantizer\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
    "\n",
    "# create ORTQuantizer and define quantization configuration\n",
    "quantizer = ORTQuantizer.from_pretrained(model_id, feature=task)\n",
    "qconfig = AutoQuantizationConfig.avx512_vnni(is_static=False, per_channel=True)\n",
    "\n",
    "# apply the quantization configuration to the model\n",
    "quantizer.export(\n",
    "    onnx_model_path=onnx_path / \"model-optimized.onnx\",\n",
    "    onnx_quantized_model_output_path=onnx_path / \"model-quantized.onnx\",\n",
    "    quantization_config=qconfig,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "On_rSehljGTs",
    "outputId": "d91d9b78-2979-4a57-862a-c9b7f59cbb01",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# load quantized model\n",
    "qt_model = ORTModelForQuestionAnswering.from_pretrained(onnx_path, file_name=\"model-quantized.onnx\")\n",
    "\n",
    "# test the quantized model with using transformers pipeline\n",
    "quantized_qa_model = pipeline(task, model=qt_model, tokenizer=tokenizer, handle_impossible_answer=True)"
   ],
   "metadata": {
    "id": "_PB9dydBSRsQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "prediction = quantized_qa_model(question=\"what is my name?\", context=\"My name is Humza and I'm 5 years old\")\n",
    "print(prediction)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnFlFRnOsbwc",
    "outputId": "5fe55f51-8037-470f-9c9e-88f38b282f58",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "P_qgfH2EsjMf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}